"""DefenderAgent â€” reactive defense generation triggered on jailbreaks.

Pipeline:
    1. Analyze the successful attack (identify technique and vulnerability)
    2. Generate defense candidates (rule-based, prompt-patch, or ML-based)
    3. Evaluate defense effectiveness (optional replay)

The generated defenses are returned in state for the graph to apply
to the TargetInterface's active defense pipeline.
"""

from __future__ import annotations

from typing import Any

import structlog

from adversarial_framework.agents.base import BaseAgent
from adversarial_framework.agents.defender.guardrail_gen import generate_guardrail
from adversarial_framework.agents.defender.patch_gen import generate_prompt_patch
from adversarial_framework.agents.target.providers.base import BaseProvider
from adversarial_framework.core.constants import DefenseType
from adversarial_framework.core.state import AdversarialState, DefenseAction, TokenBudget

logger = structlog.get_logger(__name__)


class DefenderAgent(BaseAgent):
    """LangGraph node that generates defenses against successful jailbreaks.

    Activates when the Analyzer detects a jailbreak.  Produces defense
    actions that the graph applies to the TargetInterface.
    """

    def __init__(self, config: dict[str, Any], provider: BaseProvider) -> None:
        super().__init__(config)
        self.provider = provider

    async def __call__(self, state: AdversarialState) -> dict[str, Any]:
        """Generate defenses and return them as state updates."""
        attack_prompt = state.get("current_attack_prompt", "")
        target_response = state.get("target_response", "")
        strategy_name = state.get("selected_strategy", "unknown")
        vulnerability = state.get("vulnerability_category", "unknown")
        turn_number = state.get("current_turn", 0)
        model = state.get("defender_model", self.model_name)

        logger.info(
            "defender_activated",
            turn=turn_number,
            strategy=strategy_name,
            vulnerability=vulnerability,
        )

        defense_actions: list[DefenseAction] = []
        total_tokens = 0

        # Step 1: Generate rule-based guardrail
        try:
            rule_result = await generate_guardrail(
                provider=self.provider,
                model=model,
                attack_prompt=attack_prompt or "",
                target_response=target_response or "",
                strategy_name=strategy_name or "unknown",
                vulnerability=vulnerability or "unknown",
            )
            total_tokens += rule_result.get("token_usage", 0)

            defense_actions.append(
                DefenseAction(
                    defense_type=DefenseType.RULE_BASED.value,
                    defense_config=rule_result.get("guardrail_config", {}),
                    triggered_by_turn=turn_number,
                    rationale=rule_result.get("rationale", "Auto-generated rule-based defense"),
                )
            )

            logger.info("defender_guardrail_generated", turn=turn_number)

        except Exception as exc:
            logger.error("defender_guardrail_error", error=str(exc))

        # Step 2: Generate system prompt patch
        try:
            patch_result = await generate_prompt_patch(
                provider=self.provider,
                model=model,
                attack_prompt=attack_prompt or "",
                target_response=target_response or "",
                strategy_name=strategy_name or "unknown",
                current_system_prompt=state.get("target_system_prompt", ""),
            )
            total_tokens += patch_result.get("token_usage", 0)

            defense_actions.append(
                DefenseAction(
                    defense_type=DefenseType.PROMPT_PATCH.value,
                    defense_config=patch_result.get("patch_config", {}),
                    triggered_by_turn=turn_number,
                    rationale=patch_result.get("rationale", "Auto-generated prompt patch"),
                )
            )

            logger.info("defender_patch_generated", turn=turn_number)

        except Exception as exc:
            logger.error("defender_patch_error", error=str(exc))

        logger.info(
            "defender_complete",
            turn=turn_number,
            defenses_generated=len(defense_actions),
            tokens=total_tokens,
        )

        return {
            "defense_actions": defense_actions,
            "token_budget": TokenBudget(total_defender_tokens=total_tokens),
        }

    def get_system_prompt(self, state: AdversarialState) -> str:
        """Build a context-aware system prompt for the defender."""
        return (
            "You are a security defense specialist. Your task is to analyze "
            "successful jailbreak attacks and generate effective countermeasures "
            "to prevent similar attacks in the future."
        )
